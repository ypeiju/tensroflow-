{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-441275594263>:5: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cputf\\lib\\site-packages\\tensorflow\\python\\training\\input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cputf\\lib\\site-packages\\tensorflow\\python\\training\\input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cputf\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cputf\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-441275594263>:6: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n",
      "WARNING:tensorflow:From <ipython-input-2-441275594263>:11: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "[[[55 61 35]\n",
      "  [54 60 34]\n",
      "  [55 61 33]\n",
      "  ...\n",
      "  [77 49 28]\n",
      "  [80 47 28]\n",
      "  [85 52 33]]\n",
      "\n",
      " [[55 61 35]\n",
      "  [53 59 33]\n",
      "  [52 58 30]\n",
      "  ...\n",
      "  [81 50 30]\n",
      "  [81 48 29]\n",
      "  [81 48 29]]\n",
      "\n",
      " [[56 62 34]\n",
      "  [54 60 32]\n",
      "  [53 59 31]\n",
      "  ...\n",
      "  [81 49 28]\n",
      "  [82 50 29]\n",
      "  [82 47 27]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[30 33 14]\n",
      "  [29 32 13]\n",
      "  [29 32 13]\n",
      "  ...\n",
      "  [32 42 15]\n",
      "  [32 42 17]\n",
      "  [31 41 16]]\n",
      "\n",
      " [[31 34 15]\n",
      "  [31 34 15]\n",
      "  [32 35 16]\n",
      "  ...\n",
      "  [33 43 18]\n",
      "  [33 43 18]\n",
      "  [31 41 16]]\n",
      "\n",
      " [[31 34 15]\n",
      "  [31 34 15]\n",
      "  [32 35 16]\n",
      "  ...\n",
      "  [35 45 20]\n",
      "  [36 46 21]\n",
      "  [34 44 19]]]\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "red = tf.constant([255, 0, 0])\n",
    "file_names = ['./data/blue_jay.jpg']\n",
    "filename_queue = tf.train.string_input_producer(file_names)\n",
    "image_reader = tf.WholeFileReader()\n",
    "_, image_file = image_reader.read(filename_queue)\n",
    "image = tf.image.decode_jpeg(image_file)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "print (sess.run(image))\n",
    "filename_queue.close(cancel_pending_enqueues=True)\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "print (\"------------------------------------------------------\")\n",
    "image_label = b'\\x01'\n",
    "image_loaded = sess.run(image)\n",
    "image_bytes = image_loaded.tobytes()\n",
    "image_height, image_width, image_channels = image_loaded.shape\n",
    "writer = tf.python_io.TFRecordWriter(\"./output/training-image.tfrecord\")\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_label])),\n",
    "'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
    "}))\n",
    "print(example)\n",
    "writer.write(example.SerializeToString())\n",
    "writer.close()\n",
    "print (\"------------------------------------------------------\")\n",
    "tf_record_filename_queue = tf.train.string_input_producer([\"./output/training-image.tfrecord\"])\n",
    "tf_record_reader = tf.TFRecordReader()\n",
    "_, tf_record_serialized = tf_record_reader.read(tf_record_filename_queue)\n",
    "tf_record_features = tf.parse_single_example(\n",
    "tf_record_serialized,\n",
    "features={\n",
    "'label': tf.FixedLenFeature([], tf.string),\n",
    "'image': tf.FixedLenFeature([], tf.string),\n",
    "})\n",
    "tf_record_image = tf.decode_raw(\n",
    "tf_record_features['image'], tf.uint8)\n",
    "tf_record_image = tf.reshape(tf_record_image,[image_height, image_width, image_channels])\n",
    "print(tf_record_image)\n",
    "tf_record_label = tf.cast(tf_record_features['label'], tf.string)\n",
    "print( tf_record_label)\n",
    "print(\"------------------------------------------------------\")\n",
    "#sess.close()\n",
    "#sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "print (sess.run(tf.equal(image, tf_record_image)))\n",
    "sess.run(tf_record_label)\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "print( \"------------------------------------------------------\")\n",
    "print (sess.run(tf.image.central_crop(image, 0.1)))\n",
    "real_image = sess.run(image)\n",
    "bounding_crop = tf.image.crop_to_bounding_box(\n",
    "real_image, offset_height=0, offset_width=0, target_height=2, target_width=1)\n",
    "print (sess.run(bounding_crop))\n",
    "print( \"------------------------------------------------------\")\n",
    "real_image = sess.run(image)\n",
    "pad = tf.image.pad_to_bounding_box(\n",
    "real_image, offset_height=0, offset_width=0, target_height=4, target_width=4)\n",
    "print (sess.run(pad))\n",
    "print (\"------------------------------------------------------\")\n",
    "crop_or_pad = tf.image.resize_image_with_crop_or_pad(\n",
    "real_image, target_height=2, target_width=5)\n",
    "print (sess.run(crop_or_pad))\n",
    "print (\"------------------------------------------------------\")\n",
    "#sess.close()\n",
    "#sess = tf.Session()\n",
    "top_left_pixels = tf.slice(image, [0, 0, 0], [2, 2, 3])\n",
    "flip_horizon = tf.image.flip_left_right(top_left_pixels)\n",
    "flip_vertical = tf.image.flip_up_down(flip_horizon)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "print (sess.run([top_left_pixels, flip_vertical]))\n",
    "print (\"------------------------------------------------------\")\n",
    "top_left_pixels = tf.slice(image, [0, 0, 0], [2, 2, 3])\n",
    "random_flip_horizon = tf.image.random_flip_left_right(top_left_pixels)\n",
    "random_flip_vertical = tf.image.random_flip_up_down(random_flip_horizon)\n",
    "print (sess.run(random_flip_vertical))\n",
    "print (\"------------------------------------------------------\")\n",
    "example_red_pixel = tf.constant([254., 2., 15.])\n",
    "adjust_brightness = tf.image.adjust_brightness(example_red_pixel, 0.2)\n",
    "print (sess.run(adjust_brightness))\n",
    "print (\"------------------------------------------------------\")\n",
    "adjust_contrast = tf.image.adjust_contrast(image, -.5)\n",
    "print (sess.run(tf.slice(adjust_contrast, [1, 0, 0], [1, 3, 3])))\n",
    "print (\"------------------------------------------------------\")\n",
    "adjust_hue = tf.image.adjust_hue(image, 0.7)\n",
    "print (sess.run(tf.slice(adjust_hue, [1, 0, 0], [1, 3, 3])))\n",
    "print (\"------------------------------------------------------\")\n",
    "adjust_saturation = tf.image.adjust_saturation(image, 0.4)\n",
    "print (sess.run(tf.slice(adjust_saturation, [1, 0, 0], [1, 3, 3])))\n",
    "print (\"------------------------------------------------------\")\n",
    "gray = tf.image.rgb_to_grayscale(image)\n",
    "print (sess.run(tf.slice(gray, [0, 0, 0], [1, 3, 1])))\n",
    "print (\"------------------------------------------------------\")\n",
    "hsv = tf.image.rgb_to_hsv(tf.image.convert_image_dtype(image, tf.float32))\n",
    "print (sess.run(tf.slice(hsv, [0, 0, 0], [3, 3, 3])))\n",
    "print (\"------------------------------------------------------\")\n",
    "rgb_hsv = tf.image.hsv_to_rgb(hsv)\n",
    "rgb_grayscale = tf.image.grayscale_to_rgb(gray)\n",
    "print (rgb_hsv, rgb_grayscale)\n",
    "print (\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CpuTensorflow",
   "language": "python",
   "name": "cputf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
